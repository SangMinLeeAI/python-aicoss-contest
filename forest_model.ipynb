{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import StringLookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "flpop = pd.read_csv(r'TBSM_TRDAR_FLPOP_QU.csv',  encoding = \"euc-kr\", sep=\"|\")\n",
    "stores = pd.read_csv(r'TBSM_TRDAR_STOR_QU.csv',  encoding = \"euc-kr\", sep=\"|\")\n",
    "selling = pd.read_csv(r'TBSM_TRDAR_SELNG_QU.csv',  encoding = \"euc-kr\", sep=\"|\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_data_file = \"train_data_file.csv\"\n",
    "test_data_file = \"test_data_file.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "geo_code = pd.read_csv(r'geo_code.csv', sep = \",\", encoding='euc-kr')\n",
    "sales_data = pd.read_csv(r'sales_data.csv', sep=\"|\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Drop SVC_INDUTY_CD column for join the table\n",
    "stores = stores.drop(['SVC_INDUTY_CD'], axis=1)\n",
    "selling = selling.drop(['SVC_INDUTY_CD'], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Join the table\n",
    "stores_joined = stores.merge(selling, on=['STDR_YY_CD', 'STDR_QU_CD', 'TRDAR_SE_CD', 'TRDAR_CD'])\n",
    "stores_joined = stores_joined.merge(flpop, on=['STDR_YY_CD', 'STDR_QU_CD', 'TRDAR_SE_CD', 'TRDAR_CD'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# One hot encoding on categorical data\n",
    "stores_dummy = pd.get_dummies(stores_joined, columns=['STDR_YY_CD', 'STDR_QU_CD', 'TRDAR_SE_CD', 'TRDAR_CD'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   STDR_YY_CD  STDR_QU_CD TRDAR_SE_CD  TRDAR_CD  STOR_CO_x  \\\n0        2019           1           A   2110319          4   \n1        2019           1           A   2110106          2   \n2        2019           1           A   2110174          6   \n3        2019           1           D   2120170          7   \n4        2019           1           A   2110770          2   \n\n   SIMILR_INDUTY_STOR_CO  OPBIZ_RT  OPBIZ_STOR_CO  CLSBIZ_RT  CLSBIZ_STOR_CO  \\\n0                      4      25.0              1       25.0               1   \n1                      3       0.0              0        0.0               0   \n2                      7       0.0              0       28.6               2   \n3                     11       0.0              0        9.1               1   \n4                      2       0.0              0       50.0               1   \n\n   ...  FAG_60_ABOVE_SATTM_4_FLPOP_CO  FAG_60_ABOVE_SATTM_5_FLPOP_CO  \\\n0  ...                           3739                           5551   \n1  ...                           1062                           1526   \n2  ...                           3920                           5800   \n3  ...                           2207                           2650   \n4  ...                           2115                           2685   \n\n   FAG_60_ABOVE_SATTM_6_FLPOP_CO  FAG_60_ABOVE_SUNTM_1_FLPOP_CO  \\\n0                           3635                           6119   \n1                           1045                           2024   \n2                           4823                          10597   \n3                           1121                           1608   \n4                           2533                           6090   \n\n   FAG_60_ABOVE_SUNTM_2_FLPOP_CO  FAG_60_ABOVE_SUNTM_3_FLPOP_CO  \\\n0                           5039                           3413   \n1                           1517                            927   \n2                           8153                           4093   \n3                           1671                           1722   \n4                           4642                           2234   \n\n   FAG_60_ABOVE_SUNTM_4_FLPOP_CO  FAG_60_ABOVE_SUNTM_5_FLPOP_CO  \\\n0                           3688                           5493   \n1                           1026                           1607   \n2                           4130                           5623   \n3                           1879                           2289   \n4                           1944                           2575   \n\n   FAG_60_ABOVE_SUNTM_6_FLPOP_CO    RELM_AR  \n0                           3542   95378.70  \n1                           1112   20550.44  \n2                           4561  103407.87  \n3                           1102  103761.70  \n4                           2483   47040.28  \n\n[5 rows x 610 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STDR_YY_CD</th>\n      <th>STDR_QU_CD</th>\n      <th>TRDAR_SE_CD</th>\n      <th>TRDAR_CD</th>\n      <th>STOR_CO_x</th>\n      <th>SIMILR_INDUTY_STOR_CO</th>\n      <th>OPBIZ_RT</th>\n      <th>OPBIZ_STOR_CO</th>\n      <th>CLSBIZ_RT</th>\n      <th>CLSBIZ_STOR_CO</th>\n      <th>...</th>\n      <th>FAG_60_ABOVE_SATTM_4_FLPOP_CO</th>\n      <th>FAG_60_ABOVE_SATTM_5_FLPOP_CO</th>\n      <th>FAG_60_ABOVE_SATTM_6_FLPOP_CO</th>\n      <th>FAG_60_ABOVE_SUNTM_1_FLPOP_CO</th>\n      <th>FAG_60_ABOVE_SUNTM_2_FLPOP_CO</th>\n      <th>FAG_60_ABOVE_SUNTM_3_FLPOP_CO</th>\n      <th>FAG_60_ABOVE_SUNTM_4_FLPOP_CO</th>\n      <th>FAG_60_ABOVE_SUNTM_5_FLPOP_CO</th>\n      <th>FAG_60_ABOVE_SUNTM_6_FLPOP_CO</th>\n      <th>RELM_AR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019</td>\n      <td>1</td>\n      <td>A</td>\n      <td>2110319</td>\n      <td>4</td>\n      <td>4</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>3739</td>\n      <td>5551</td>\n      <td>3635</td>\n      <td>6119</td>\n      <td>5039</td>\n      <td>3413</td>\n      <td>3688</td>\n      <td>5493</td>\n      <td>3542</td>\n      <td>95378.70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019</td>\n      <td>1</td>\n      <td>A</td>\n      <td>2110106</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1062</td>\n      <td>1526</td>\n      <td>1045</td>\n      <td>2024</td>\n      <td>1517</td>\n      <td>927</td>\n      <td>1026</td>\n      <td>1607</td>\n      <td>1112</td>\n      <td>20550.44</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019</td>\n      <td>1</td>\n      <td>A</td>\n      <td>2110174</td>\n      <td>6</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>28.6</td>\n      <td>2</td>\n      <td>...</td>\n      <td>3920</td>\n      <td>5800</td>\n      <td>4823</td>\n      <td>10597</td>\n      <td>8153</td>\n      <td>4093</td>\n      <td>4130</td>\n      <td>5623</td>\n      <td>4561</td>\n      <td>103407.87</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019</td>\n      <td>1</td>\n      <td>D</td>\n      <td>2120170</td>\n      <td>7</td>\n      <td>11</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>9.1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2207</td>\n      <td>2650</td>\n      <td>1121</td>\n      <td>1608</td>\n      <td>1671</td>\n      <td>1722</td>\n      <td>1879</td>\n      <td>2289</td>\n      <td>1102</td>\n      <td>103761.70</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019</td>\n      <td>1</td>\n      <td>A</td>\n      <td>2110770</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2115</td>\n      <td>2685</td>\n      <td>2533</td>\n      <td>6090</td>\n      <td>4642</td>\n      <td>2234</td>\n      <td>1944</td>\n      <td>2575</td>\n      <td>2483</td>\n      <td>47040.28</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 610 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_joined.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# target data convert to categorical data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df = stores_joined.sample(frac = 1)\n",
    "df['per_INDUTY'] = df['SIMILR_INDUTY_STOR_CO'] / df[\"RELM_AR\"]\n",
    "# df['SIMILR_INDUTY_STOR_CO'] = pd.cut(df.SIMILR_INDUTY_STOR_CO, bins=5,\n",
    "#                                  labels=False, include_lowest=True)\n",
    "df['SIMILR_INDUTY_STOR_CO'] = pd.qcut(df.SIMILR_INDUTY_STOR_CO, q=5, precision=1, labels=[\"very low\", \"low\", \"medium\", \"high\", \"very high\"])\n",
    "# column type to str\n",
    "df = df.astype({'STDR_YY_CD': 'str', 'STDR_QU_CD': 'str', 'TRDAR_SE_CD': 'str', 'TRDAR_CD': 'str'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.000135    15\n0.000100    15\n0.000030    15\n0.000156    15\n0.000026    15\n            ..\n0.000159     1\n0.000062     1\n0.000238     1\n0.000156     1\n0.000329     1\nName: per_INDUTY, Length: 6095, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.per_INDUTY.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "3      1654\n4      1611\n2      1608\n5      1442\n6      1229\n       ... \n174       1\n155       1\n193       1\n177       1\n270       1\nName: SIMILR_INDUTY_STOR_CO, Length: 212, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_joined.SIMILR_INDUTY_STOR_CO.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "12029          low\n7616           low\n4323      very low\n12680       medium\n11998          low\n           ...    \n12814       medium\n18351    very high\n5964      very low\n7565        medium\n12083         high\nName: SIMILR_INDUTY_STOR_CO, Length: 18448, dtype: category\nCategories (5, object): ['very low' < 'low' < 'medium' < 'high' < 'very high']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.SIMILR_INDUTY_STOR_CO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test train split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "split_idx = math.floor(len(df)*0.8)\n",
    "train_data = df.iloc[:split_idx,:]\n",
    "test_data = df.iloc[split_idx:,:]\n",
    "train_data.to_csv(\"train_data_file.csv\", index = False, header = False)\n",
    "test_data.to_csv(\"test_data_file.csv\", index = False, header = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "very low     4493\nmedium       4142\nvery high    3557\nhigh         3203\nlow          3053\nName: SIMILR_INDUTY_STOR_CO, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SIMILR_INDUTY_STOR_CO'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification with Neural Decision Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- https://keras.io/examples/structured_data/deep_neural_decision_forests/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.000135    15\n0.000100    15\n0.000030    15\n0.000156    15\n0.000026    15\n            ..\n0.000159     1\n0.000062     1\n0.000238     1\n0.000156     1\n0.000329     1\nName: per_INDUTY, Length: 6095, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.per_INDUTY.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# A list of the numerical feature names.\n",
    "names = [list(df.columns)[4]]\n",
    "names.extend(list(df.columns)[6:])\n",
    "NUMERIC_FEATURE_NAMES =  names\n",
    "\n",
    "# A dictionary of the categorical features and their vocabulary.\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"STDR_YY_CD\": sorted(list(train_data[\"STDR_YY_CD\"].unique())),\n",
    "    \"STDR_QU_CD\": sorted(list(train_data[\"STDR_QU_CD\"].unique())),\n",
    "    \"TRDAR_SE_CD\": sorted(list(train_data[\"TRDAR_SE_CD\"].unique())),\n",
    "    \"TRDAR_CD\": sorted(list(train_data[\"TRDAR_CD\"].unique())),\n",
    "}\n",
    "# A list of the columns to ignore from the dataset.\n",
    "IGNORE_COLUMN_NAMES = [\"per_INDUTY\"]\n",
    "# A list of the categorical feature names.\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "# A list of all the input features.\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "# A list of column default values for each feature.\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in NUMERIC_FEATURE_NAMES + IGNORE_COLUMN_NAMES else [\"NA\"]\n",
    "    for feature_name in list(train_data.columns)\n",
    "]\n",
    "# The name of the target feature.\n",
    "TARGET_FEATURE_NAME = \"SIMILR_INDUTY_STOR_CO\"\n",
    "# A list of the labels of the target features.\n",
    "TARGET_LABELS = [\"very low\", \"low\", \"medium\", \"high\", \"very high\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "611"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_data.columns))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "611"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv(\"train_data_file.csv\", header = None).columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/numpy/core/numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_label_lookup = StringLookup(\n",
    "    vocabulary=TARGET_LABELS, mask_token=None, num_oov_indices=0\n",
    ")\n",
    "\n",
    "\n",
    "def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=128):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=list(df.columns),\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=False,\n",
    "        na_value=\"?\",\n",
    "        shuffle=shuffle,\n",
    "    ).map(lambda features, target: (features, target_label_lookup(target)))\n",
    "    return dataset.cache()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def encode_inputs(inputs):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            # Create a lookup to convert a string values to an integer indices.\n",
    "            # Since we are not using a mask token, nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and num_oov_indices to 0.\n",
    "            lookup = StringLookup(\n",
    "                vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
    "            )\n",
    "            # Convert the string input values into integer indices.\n",
    "            value_index = lookup(inputs[feature_name])\n",
    "            embedding_dims = int(math.sqrt(lookup.vocabulary_size()))\n",
    "            # Create an embedding layer with the specified dimensions.\n",
    "            embedding = layers.Embedding(\n",
    "                input_dim=lookup.vocabulary_size(), output_dim=embedding_dims\n",
    "            )\n",
    "            # Convert the index values to embedding representations.\n",
    "            encoded_feature = embedding(value_index)\n",
    "        else:\n",
    "            # Use the numerical features as-is.\n",
    "            encoded_feature = inputs[feature_name]\n",
    "            if inputs[feature_name].shape[-1] is None:\n",
    "                encoded_feature = tf.expand_dims(encoded_feature, -1)\n",
    "\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    encoded_features = layers.concatenate(encoded_features)\n",
    "    return encoded_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class NeuralDecisionTree(keras.Model):\n",
    "    def __init__(self, depth, num_features, used_features_rate, num_classes):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.num_leaves = 2 ** depth\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Create a mask for the randomly selected features.\n",
    "        num_used_features = int(num_features * used_features_rate)\n",
    "        one_hot = np.eye(num_features)\n",
    "        sampled_feature_indicies = np.random.choice(\n",
    "            np.arange(num_features), num_used_features, replace=False\n",
    "        )\n",
    "        self.used_features_mask = one_hot[sampled_feature_indicies]\n",
    "\n",
    "        # Initialize the weights of the classes in leaves.\n",
    "        self.pi = tf.Variable(\n",
    "            initial_value=tf.random_normal_initializer()(\n",
    "                shape=[self.num_leaves, self.num_classes]\n",
    "            ),\n",
    "            dtype=\"float32\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # Initialize the stochastic routing layer.\n",
    "        self.decision_fn = layers.Dense(\n",
    "            units=self.num_leaves, activation=\"sigmoid\", name=\"decision\"\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        batch_size = tf.shape(features)[0]\n",
    "\n",
    "        # Apply the feature mask to the input features.\n",
    "        features = tf.matmul(\n",
    "            features, self.used_features_mask, transpose_b=True\n",
    "        )  # [batch_size, num_used_features]\n",
    "        # Compute the routing probabilities.\n",
    "        decisions = tf.expand_dims(\n",
    "            self.decision_fn(features), axis=2\n",
    "        )  # [batch_size, num_leaves, 1]\n",
    "        # Concatenate the routing probabilities with their complements.\n",
    "        decisions = layers.concatenate(\n",
    "            [decisions, 1 - decisions], axis=2\n",
    "        )  # [batch_size, num_leaves, 2]\n",
    "\n",
    "        mu = tf.ones([batch_size, 1, 1])\n",
    "\n",
    "        begin_idx = 1\n",
    "        end_idx = 2\n",
    "        # Traverse the tree in breadth-first order.\n",
    "        for level in range(self.depth):\n",
    "            mu = tf.reshape(mu, [batch_size, -1, 1])  # [batch_size, 2 ** level, 1]\n",
    "            mu = tf.tile(mu, (1, 1, 2))  # [batch_size, 2 ** level, 2]\n",
    "            level_decisions = decisions[\n",
    "                :, begin_idx:end_idx, :\n",
    "            ]  # [batch_size, 2 ** level, 2]\n",
    "            mu = mu * level_decisions  # [batch_size, 2**level, 2]\n",
    "            begin_idx = end_idx\n",
    "            end_idx = begin_idx + 2 ** (level + 1)\n",
    "\n",
    "        mu = tf.reshape(mu, [batch_size, self.num_leaves])  # [batch_size, num_leaves]\n",
    "        probabilities = keras.activations.softmax(self.pi)  # [num_leaves, num_classes]\n",
    "        outputs = tf.matmul(mu, probabilities)  # [batch_size, num_classes]\n",
    "        return outputs\n",
    "class NeuralDecisionForest(keras.Model):\n",
    "    def __init__(self, num_trees, depth, num_features, used_features_rate, num_classes):\n",
    "        super().__init__()\n",
    "        self.ensemble = []\n",
    "        # Initialize the ensemble by adding NeuralDecisionTree instances.\n",
    "        # Each tree will have its own randomly selected input features to use.\n",
    "        for _ in range(num_trees):\n",
    "            self.ensemble.append(\n",
    "                NeuralDecisionTree(depth, num_features, used_features_rate, num_classes)\n",
    "            )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Initialize the outputs: a [batch_size, num_classes] matrix of zeros.\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        outputs = tf.zeros([batch_size, num_classes])\n",
    "\n",
    "        # Aggregate the outputs of trees in the ensemble.\n",
    "        for tree in self.ensemble:\n",
    "            outputs += tree(inputs)\n",
    "        # Divide the outputs by the ensemble size to get the average.\n",
    "        outputs /= len(self.ensemble)\n",
    "        return outputs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 265\n",
    "num_epochs = 10\n",
    "hidden_units = [64, 64]\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    train_dataset = get_dataset_from_csv(\n",
    "        train_data_file, shuffle=False, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "    model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    print(\"Evaluating the model on the test data...\")\n",
    "    test_dataset = get_dataset_from_csv(test_data_file, batch_size=batch_size)\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "WARNING:tensorflow:From /Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 00:21:37.407743: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 [==============================] - 7s 80ms/step - loss: 1.3618 - sparse_categorical_accuracy: 0.5573\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.8847 - sparse_categorical_accuracy: 0.7609\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.6358 - sparse_categorical_accuracy: 0.8189\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.4959 - sparse_categorical_accuracy: 0.8601\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.3989 - sparse_categorical_accuracy: 0.8900\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.3478 - sparse_categorical_accuracy: 0.9036\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.3073 - sparse_categorical_accuracy: 0.9154\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.2842 - sparse_categorical_accuracy: 0.9228\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.2636 - sparse_categorical_accuracy: 0.9293\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.2460 - sparse_categorical_accuracy: 0.9331\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "      4/Unknown - 2s 72ms/step - loss: 0.3415 - sparse_categorical_accuracy: 0.8906"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/string_lookup_4/Assert/Assert' defined at (most recent call last):\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/dl/lcgqt2hd0vd6rfg593dgmnkh0000gn/T/ipykernel_39094/2483583521.py\", line 21, in <module>\n      run_experiment(tree_model)\n    File \"/var/folders/dl/lcgqt2hd0vd6rfg593dgmnkh0000gn/T/ipykernel_39094/3423854438.py\", line 27, in run_experiment\n      _, accuracy = model.evaluate(test_dataset)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 2040, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1820, in test_function\n      return step_function(self, iterator)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1804, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1792, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1756, in test_step\n      y_pred = self(x, training=False)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 747, in call\n      lookups = self._lookup_dense(inputs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 803, in _lookup_dense\n      assertion = tf.Assert(tf.equal(tf.size(oov_indices), 0), [msg])\nNode: 'model/string_lookup_4/Assert/Assert'\nassertion failed: [When `num_oov_indices=0` all inputs should be in vocabulary, found OOV values [\\\"2110265\\\"], consider setting `num_oov_indices=1`.]\n\t [[{{node model/string_lookup_4/Assert/Assert}}]] [Op:__inference_test_function_23387]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 21\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m     20\u001B[0m tree_model \u001B[38;5;241m=\u001B[39m create_tree_model()\n\u001B[0;32m---> 21\u001B[0m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtree_model\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[23], line 27\u001B[0m, in \u001B[0;36mrun_experiment\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating the model on the test data...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     25\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m get_dataset_from_csv(test_data_file, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[0;32m---> 27\u001B[0m _, accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(accuracy\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m100\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.conda/envs/python-camp-contest/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'model/string_lookup_4/Assert/Assert' defined at (most recent call last):\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/dl/lcgqt2hd0vd6rfg593dgmnkh0000gn/T/ipykernel_39094/2483583521.py\", line 21, in <module>\n      run_experiment(tree_model)\n    File \"/var/folders/dl/lcgqt2hd0vd6rfg593dgmnkh0000gn/T/ipykernel_39094/3423854438.py\", line 27, in run_experiment\n      _, accuracy = model.evaluate(test_dataset)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 2040, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1820, in test_function\n      return step_function(self, iterator)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1804, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1792, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1756, in test_step\n      y_pred = self(x, training=False)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 747, in call\n      lookups = self._lookup_dense(inputs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 803, in _lookup_dense\n      assertion = tf.Assert(tf.equal(tf.size(oov_indices), 0), [msg])\nNode: 'model/string_lookup_4/Assert/Assert'\nassertion failed: [When `num_oov_indices=0` all inputs should be in vocabulary, found OOV values [\\\"2110265\\\"], consider setting `num_oov_indices=1`.]\n\t [[{{node model/string_lookup_4/Assert/Assert}}]] [Op:__inference_test_function_23387]"
     ]
    }
   ],
   "source": [
    "num_trees = 10\n",
    "depth = 10\n",
    "used_features_rate = 1.0\n",
    "num_classes = len(TARGET_LABELS)\n",
    "\n",
    "\n",
    "def create_tree_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "    num_features = features.shape[1]\n",
    "\n",
    "    tree = NeuralDecisionTree(depth, num_features, used_features_rate, num_classes)\n",
    "\n",
    "    outputs = tree(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "tree_model = create_tree_model()\n",
    "run_experiment(tree_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/numpy/core/numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/10\n",
      "56/56 [==============================] - 11s 77ms/step - loss: 1.3617 - sparse_categorical_accuracy: 0.6134\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 0.8173 - sparse_categorical_accuracy: 0.8261\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 0.5244 - sparse_categorical_accuracy: 0.8694\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 0.3884 - sparse_categorical_accuracy: 0.8942\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.3178 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 0.2727 - sparse_categorical_accuracy: 0.9171\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2421 - sparse_categorical_accuracy: 0.9245\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.9253\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 0.2068 - sparse_categorical_accuracy: 0.9297\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1925 - sparse_categorical_accuracy: 0.9339\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "      4/Unknown - 3s 66ms/step - loss: 0.2689 - sparse_categorical_accuracy: 0.9038"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/string_lookup_8/Assert/Assert' defined at (most recent call last):\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/dl/lcgqt2hd0vd6rfg593dgmnkh0000gn/T/ipykernel_39094/1727455595.py\", line 23, in <module>\n      run_experiment(forest_model)\n    File \"/var/folders/dl/lcgqt2hd0vd6rfg593dgmnkh0000gn/T/ipykernel_39094/3423854438.py\", line 27, in run_experiment\n      _, accuracy = model.evaluate(test_dataset)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 2040, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1820, in test_function\n      return step_function(self, iterator)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1804, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1792, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1756, in test_step\n      y_pred = self(x, training=False)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 747, in call\n      lookups = self._lookup_dense(inputs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 803, in _lookup_dense\n      assertion = tf.Assert(tf.equal(tf.size(oov_indices), 0), [msg])\nNode: 'model_1/string_lookup_8/Assert/Assert'\nassertion failed: [When `num_oov_indices=0` all inputs should be in vocabulary, found OOV values [\\\"2110265\\\"], consider setting `num_oov_indices=1`.]\n\t [[{{node model_1/string_lookup_8/Assert/Assert}}]] [Op:__inference_test_function_69427]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 23\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m     21\u001B[0m forest_model \u001B[38;5;241m=\u001B[39m create_forest_model()\n\u001B[0;32m---> 23\u001B[0m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mforest_model\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[23], line 27\u001B[0m, in \u001B[0;36mrun_experiment\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating the model on the test data...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     25\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m get_dataset_from_csv(test_data_file, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[0;32m---> 27\u001B[0m _, accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(accuracy\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m100\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.conda/envs/python-camp-contest/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'model_1/string_lookup_8/Assert/Assert' defined at (most recent call last):\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/dl/lcgqt2hd0vd6rfg593dgmnkh0000gn/T/ipykernel_39094/1727455595.py\", line 23, in <module>\n      run_experiment(forest_model)\n    File \"/var/folders/dl/lcgqt2hd0vd6rfg593dgmnkh0000gn/T/ipykernel_39094/3423854438.py\", line 27, in run_experiment\n      _, accuracy = model.evaluate(test_dataset)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 2040, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1820, in test_function\n      return step_function(self, iterator)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1804, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1792, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 1756, in test_step\n      y_pred = self(x, training=False)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 747, in call\n      lookups = self._lookup_dense(inputs)\n    File \"/Users/min/.conda/envs/python-camp-contest/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 803, in _lookup_dense\n      assertion = tf.Assert(tf.equal(tf.size(oov_indices), 0), [msg])\nNode: 'model_1/string_lookup_8/Assert/Assert'\nassertion failed: [When `num_oov_indices=0` all inputs should be in vocabulary, found OOV values [\\\"2110265\\\"], consider setting `num_oov_indices=1`.]\n\t [[{{node model_1/string_lookup_8/Assert/Assert}}]] [Op:__inference_test_function_69427]"
     ]
    }
   ],
   "source": [
    "num_trees = 25\n",
    "depth = 5\n",
    "used_features_rate = 0.5\n",
    "\n",
    "\n",
    "def create_forest_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "    num_features = features.shape[1]\n",
    "\n",
    "    forest_model = NeuralDecisionForest(\n",
    "        num_trees, depth, num_features, used_features_rate, num_classes\n",
    "    )\n",
    "\n",
    "    outputs = forest_model(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "forest_model = create_forest_model()\n",
    "\n",
    "run_experiment(forest_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
